

2024-07-17 11:19

Status:

Tags:

## mutual information

Mutual information is a measure of the mutual dependence between two variables.
It quantifies the amount of information obtained about one random variable through observing the other random variable
if we have random variable X and Y.
and i know the distribution of X if the MI is high i'l know much about the distribution of Y as well.
### Definition
![[Pasted image 20240717112554.png]]

properties:
$$
I(X;Y)\geq 0
$$
$$
I(X;Y) = I(Y;X)
$$
$$
I(X;Y) = H(X) + H(Y) - H(X,Y)
$$

H is the [[Entropy]]



## References

